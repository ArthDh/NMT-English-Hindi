{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nmt-eng-hin.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"8b3PApsNYYa4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":105},"outputId":"0790a49d-8725-4cb0-8502-dc4e7d7d908c","executionInfo":{"status":"ok","timestamp":1531300509335,"user_tz":-330,"elapsed":14916,"user":{"displayName":"Arth Dharaskar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112750200661093479151"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"VSjK6urKZOls","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"f8377cd6-d687-43b2-ecc1-ab26f4d90ad1","executionInfo":{"status":"ok","timestamp":1531306899071,"user_tz":-330,"elapsed":1065,"user":{"displayName":"Arth Dharaskar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112750200661093479151"}}},"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n"],"execution_count":91,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"TB0YPUZZYa6h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"1211f103-003c-42d0-840f-aa7ad1b5b175","executionInfo":{"status":"ok","timestamp":1531306902334,"user_tz":-330,"elapsed":3183,"user":{"displayName":"Arth Dharaskar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112750200661093479151"}}},"cell_type":"code","source":["# !mkdir -p drive\n","# !google-drive-ocamlfuse drive\n","!ls\n","!free -g"],"execution_count":92,"outputs":[{"output_type":"stream","text":["datalab  drive\n","              total        used        free      shared  buff/cache   available\n","Mem:             12           1           0           0          10          10\n","Swap:             0           0           0\n"],"name":"stdout"}]},{"metadata":{"id":"af1IuTfcYUjn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Using Keras functional model\n","import keras\n","from keras.models import Model\n","from keras.models import load_model\n","from keras.layers import Input, Dense, LSTM\n","# Used for feeding data in Input \n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YzdNUiP6YUjw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["batch_size =64 # Batchsize for network\n","epochs = 50 # Number of epochs\n","latent_dim = 256 # Number of LSTM cells\n","num_samples = 2000 # Number of samples"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L-g_X-b8YUjy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["input_texts = [] # List of Input(English sentences)\n","target_texts = [] # List of Target(Hindi sentences)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g7KRLCs4YUj1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["input_chars = [] # List of unique english characters\n","target_chars = [] # List of unique hindi characters"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9D-u_LTIYUj5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["file_path = 'drive/projects/nmt-hindi-english/data/eng-hin.txt' # Path to english hindi text file"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WwpZxoSqYUj8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# reading file into lines\n","with open(file_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VKTb0We1YUj-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["for line in lines[:max(num_samples, len(lines)-1)]:\n","    input_text, target_text = line.split('\\t') # Splitting using tabspaces\n","    target_text = '\\t' + target_text + '\\n' # Using \\n token to signify EOS \n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","    # Used to get unique characters\n","    for char in input_text:\n","        if char not in input_chars:\n","            input_chars.append(char)\n","    for char in target_text:\n","        if char not in target_chars:\n","            target_chars.append(char)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0axpymAzYUkB","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["input_chars = sorted(input_chars)\n","target_chars = sorted(target_chars) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"WSW6F9IXYUkE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"14d1e6d4-7bce-465e-e7be-ccdddb60906b","executionInfo":{"status":"ok","timestamp":1531306915435,"user_tz":-330,"elapsed":900,"user":{"displayName":"Arth Dharaskar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112750200661093479151"}}},"cell_type":"code","source":["num_encoder_tokens = len(input_chars)\n","num_decoder_tokens = len(target_chars)\n","max_encoder_seq_length = max([len(seq) for seq in input_texts]) # Maximum sequence length for english sentences\n","max_decoder_seq_length = max([len(seq) for seq in target_texts]) # Maximum sequence length for hindi sentences\n","max_encoder_seq_length,max_decoder_seq_length"],"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(124, 123)"]},"metadata":{"tags":[]},"execution_count":101}]},{"metadata":{"id":"Vx7d2L4XYUkJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Mapping character tokens to indices\n","input_token_index = dict( [(char, i) for i,char in enumerate(input_chars)])\n","target_token_index = dict( [(char, i) for i,char in enumerate(target_chars)])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U1l8dPHqYUkM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype= 'float32')\n","decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype= 'float32')\n","decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, num_decoder_tokens), dtype= 'float32')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ec8Xv_A4YUkO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# One-hot encoding input\n","for i, input_text in enumerate(input_texts):\n","    for j, ch in enumerate(input_text):\n","        encoder_input_data[i,j,input_token_index[ch]] =1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"70kFL8AAYUkS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# One-hot encoding output\n","for i, target_text in enumerate(target_texts):\n","    for j, ch in enumerate(target_text):\n","        decoder_input_data[i,j,target_token_index[ch]] =1\n","        if j>0:\n","            decoder_target_data[i, j-1, target_token_index[ch]]=1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yU-IOTM4YUkW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Defining Encoder model\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state = True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VddZbBi0YUkb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["encoder_states = [state_h, state_c]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gwwxF4hIYUkf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Defining Decoder model\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_state = True, return_sequences = True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state= encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation = 'softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sDWEra4qYUkk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","# model = load_model('drive/projects/nmt-hindi-english/models/last_chkpt.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iNCXzQmJYUkp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["model.compile(optimizer = 'rmsprop', loss= 'categorical_crossentropy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RTGUyzSpxzl8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["callbacks_list = [\n","        keras.callbacks.ReduceLROnPlateau(\n","            monitor='loss',\n","            factor=0.1,\n","            patience=10,\n","        ),\n","]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wfcZK8hLYUkr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":717},"outputId":"1d54df88-9105-4f46-b5ca-b27a86663a1e","executionInfo":{"status":"ok","timestamp":1531308485917,"user_tz":-330,"elapsed":645914,"user":{"displayName":"Arth Dharaskar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112750200661093479151"}}},"cell_type":"code","source":["history = model.fit([encoder_input_data,decoder_input_data], decoder_target_data,\\\n","                    batch_size= batch_size, epochs=20, callbacks = callbacks_list)"],"execution_count":162,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","2867/2867 [==============================] - 37s 13ms/step - loss: 0.9202\n","Epoch 2/20\n","2867/2867 [==============================] - 33s 11ms/step - loss: 0.8510\n","Epoch 3/20\n","2867/2867 [==============================] - 33s 11ms/step - loss: 0.7713\n","Epoch 4/20\n","2867/2867 [==============================] - 31s 11ms/step - loss: 0.7014\n","Epoch 5/20\n","2867/2867 [==============================] - 30s 10ms/step - loss: 0.6472\n","Epoch 6/20\n","2867/2867 [==============================] - 31s 11ms/step - loss: 0.6103\n","Epoch 7/20\n","2112/2867 [=====================>........] - ETA: 8s - loss: 0.6071"],"name":"stdout"},{"output_type":"stream","text":["2867/2867 [==============================] - 33s 11ms/step - loss: 0.5990\n","Epoch 8/20\n","2867/2867 [==============================] - 33s 11ms/step - loss: 0.5633\n","Epoch 9/20\n","2867/2867 [==============================] - 33s 12ms/step - loss: 0.5482\n","Epoch 10/20\n","2867/2867 [==============================] - 32s 11ms/step - loss: 0.5336\n","Epoch 11/20\n","2867/2867 [==============================] - 30s 11ms/step - loss: 0.5221\n","Epoch 12/20\n","2867/2867 [==============================] - 30s 10ms/step - loss: 0.5113\n","Epoch 13/20\n","2624/2867 [==========================>...] - ETA: 2s - loss: 0.5025"],"name":"stdout"},{"output_type":"stream","text":["2867/2867 [==============================] - 33s 11ms/step - loss: 0.5012\n","Epoch 14/20\n","2867/2867 [==============================] - 33s 12ms/step - loss: 0.4921\n","Epoch 15/20\n","2867/2867 [==============================] - 33s 12ms/step - loss: 0.4836\n","Epoch 16/20\n","2867/2867 [==============================] - 32s 11ms/step - loss: 0.4830\n","Epoch 17/20\n","2867/2867 [==============================] - 30s 11ms/step - loss: 0.4773\n","Epoch 18/20\n","2867/2867 [==============================] - 30s 11ms/step - loss: 0.4651\n","Epoch 19/20\n","2688/2867 [===========================>..] - ETA: 2s - loss: 0.4595"],"name":"stdout"},{"output_type":"stream","text":["2867/2867 [==============================] - 33s 11ms/step - loss: 0.4567\n","Epoch 20/20\n","2867/2867 [==============================] - 33s 12ms/step - loss: 0.4493\n"],"name":"stdout"}]},{"metadata":{"id":"emD9cqxfyu0g","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":71},"outputId":"bb01c4b8-4d10-4f8f-fcb2-8db2b7b7b956","executionInfo":{"status":"ok","timestamp":1531308491627,"user_tz":-330,"elapsed":5629,"user":{"displayName":"Arth Dharaskar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112750200661093479151"}}},"cell_type":"code","source":["model.save('drive/projects/nmt-hindi-english/models/temp_chkpt.h5')"],"execution_count":163,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_12 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_11/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_11/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  str(node.arguments) + '. They will not be included '\n"],"name":"stderr"}]},{"metadata":{"id":"t8SplQi00InW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# model = load_model('drive/projects/nmt-hindi-english/models/last_chkpt.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qP2XzMVtnr5N","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def sample(preds, temperature= 1.0):\n","    preds = np.reshape(preds,preds.shape[-1])\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds)/ temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1,preds, 1)\n","    return np.argmax(probas)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"irHZFq06YUkx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Defining inference model\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","# Reverse-lookup token index to decode sequences back to\n","# something readable.\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_nqhVCeyYUkz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        next_index = sample(output_tokens,0.5)\n","#         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[next_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, next_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-xaEBA_MYUk2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def make_inference(sentence):\n","    input_data= np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype= 'float32')\n","    for j, ch in enumerate(sentence):\n","        input_data[0,j,input_token_index[ch]] =1\n","    decoded_sentence = decode_sequence(input_data)\n","    print('Input sentence:', sentence)\n","    print('Translated sentence:', decoded_sentence)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Bus-pXJSYUk_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":697},"outputId":"c0e2e4eb-5b2d-4d90-ae5f-99be98928e58","executionInfo":{"status":"ok","timestamp":1531308558484,"user_tz":-330,"elapsed":2751,"user":{"displayName":"Arth Dharaskar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112750200661093479151"}}},"cell_type":"code","source":["for seq_index in range(10):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    input_seq = encoder_input_data[seq_index: seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print('-')\n","    print('Input sentence:', input_texts[seq_index])\n","    print('Decoded sentence:', decoded_sentence)"],"execution_count":179,"outputs":[{"output_type":"stream","text":["-\n","Input sentence: Wow!\n","Decoded sentence: वह कुम बाल के बार अपने का समझ क्या है।\n","\n","-\n","Input sentence: Help!\n","Decoded sentence: तुम्हें कर दिया।\n","\n","-\n","Input sentence: Jump.\n","Decoded sentence: मुझे अपनी उसकी समी पर गया है।\n","\n","-\n","Input sentence: Jump.\n","Decoded sentence: को को मुझे ज़्दद कर सकते हैं।\n","\n","-\n","Input sentence: Jump.\n","Decoded sentence: उसकी बार कर से में कल समय कर नहीं है।\n","\n","-\n","Input sentence: Hello!\n","Decoded sentence: मुझे अपने कार करने को मुझे किया था।\n","\n","-\n","Input sentence: Hello!\n","Decoded sentence: वह तम अपने साम को मुझे में उसे पाल तुम्हें हैं।\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: मुझे अपने अपने को गोड़ कर बार कर रही है।\n","\n","-\n","Input sentence: Cheers!\n","Decoded sentence: उसने मुझे अपनी आद की बार शोन कर दिया।\n","\n","-\n","Input sentence: Got it?\n","Decoded sentence: मैं तुम्हें पर्चा किया था।\n","\n"],"name":"stdout"}]},{"metadata":{"id":"luEhGJSpYUlG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}